{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao3Vhg9URjX5"
      },
      "source": [
        "# üê∂End-to-end Multiclass Dog Breed Classification\n",
        "\n",
        "This notebook builds an end-to-end multi class image classifier using Tensorflow 2.x and Tensorflow Hub.\n",
        "\n",
        "## 1. Problem\n",
        "\n",
        "Identify the breed of the dog by the given image of the dog.\n",
        "\n",
        "When I'm sitting at the cafe and I take a photo of a dog, I want to know what breed of dog it is.\n",
        "\n",
        "\n",
        "## 2. Data\n",
        "\n",
        "\n",
        "The data we're using is from Kaggle's dog breed identification competition.\n",
        "\n",
        "https://www.kaggle.com/c/dog-breed-identification/data\n",
        "\n",
        "\n",
        "## 3. Evaluation\n",
        "\n",
        "The evaluation is a file with prediction probabilities for each dog breed of each test image.\n",
        "\n",
        "https://www.kaggle.com/c/dog-breed-identification/overview/evaluation\n",
        "\n",
        "\n",
        "## 4. Features\n",
        "\n",
        "Some features about data:\n",
        "* We're are dealing with images (unstructured data) so it's probably best to use deep learning/ transfer learning.\n",
        "* There are 120 different breeds of dogs (This means there are 120 different classes).\n",
        "* There are 10,000+ images in the  training set (these images have labels).\n",
        "* There are 10,000+ images in the test set (these images have no labels since we'll be predicting  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wdeBkibuTz79"
      },
      "outputs": [],
      "source": [
        "# Unzip the data\n",
        "# !unzip \"/content/drive/MyDrive/Colab Notebooks/Dog Vision /dog-breed-identification.zip\" -d \"/content/drive/MyDrive/Colab Notebooks/Dog Vision \""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpkBazvrRCH8"
      },
      "source": [
        "## Get our workspace ready\n",
        "\n",
        "- Import Tensorflow 2.x ‚úÖ\n",
        "- Import Tensorflow Hub ‚úÖ\n",
        "- Make sure we're using a GPU ‚úÖ"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aldb_x6swdn-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "R81UDpNlVZCh",
        "outputId": "c482c401-73c9-4906-b957-bf3659121bee"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'register_load_context_function'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d12a3882fece>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import Tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_hub\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensorflow version:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensorflow_hub version:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    109\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m \u001b[0m_ensure_keras_2_importable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/__init__.py\u001b[0m in \u001b[0;36m_ensure_keras_2_importable\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mversion_fn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mversion_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m       \u001b[0;32mimport\u001b[0m \u001b[0mtf_keras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0;31m# Print more informative error message, then reraise.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/__internal__/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/__internal__/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_initialize_variables\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minitialize_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrack_variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \"\"\"\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/applications/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvNeXtBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvNeXtLarge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConvNeXtSmall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/applications/convnext.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimagenet_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtraining_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/sequential.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnode_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtraining_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialization_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msaving_api\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msaving_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialization_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msaving_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlegacy_sm_saving_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/saving/legacy/save.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msaved_model_save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtf_keras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_option_scope\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/saving/legacy/saved_model/load_context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_load_context_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_load_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'register_load_context_function'"
          ]
        }
      ],
      "source": [
        "# Import Tensorflow\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "print(\"Tensorflow version:\", tf.__version__)\n",
        "print(\"Tensorflow_hub version:\", hub.__version__)\n",
        "\n",
        "# Check for GPU availability\n",
        "print(\"GPU\", \"available (YES!)\" if tf.config.list_physical_devices(\"GPU\") else\n",
        "      \"not available :(\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDSGYdMLV5cq"
      },
      "source": [
        "## Getting our data ready (turning into tensors)\n",
        "\n",
        "With all machine learning models, our data  has to be in numerical format.So that's what we will be doing first.Turning our images into Tensors(numerical representation).\n",
        "\n",
        "Let's start by accessing our data and checking out the labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kvjUDid0OSM"
      },
      "outputs": [],
      "source": [
        "# check out the label of the data\n",
        "\n",
        "import pandas as pd\n",
        "labels_csv = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Dog Vision/labels.csv\")\n",
        "labels_csv.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQdAyPcv15x1"
      },
      "outputs": [],
      "source": [
        "labels_csv.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlqfSIcS2JVz"
      },
      "outputs": [],
      "source": [
        "# how many images are there in each breed?\n",
        "labels_csv[\"breed\"].value_counts().plot.bar(figsize=(20,10));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwHNq1g_3KFd"
      },
      "outputs": [],
      "source": [
        "# What's the median number of images per class?\n",
        "labels_csv[\"breed\"].value_counts().median()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POZNCFrn3zez"
      },
      "outputs": [],
      "source": [
        "# lets view an image\n",
        "from IPython.display import Image\n",
        "Image(\"/content/drive/MyDrive/Colab Notebooks/Dog Vision/train/000bec180eb18c7604dcecc8fe0dba07.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSROPJ-L4wlE"
      },
      "source": [
        "### Getting Images and their labels\n",
        "\n",
        "Let's get a list of all our images file pathnames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zBBa9yhef6i"
      },
      "outputs": [],
      "source": [
        "labels_csv.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FW4nWHTVemBX"
      },
      "outputs": [],
      "source": [
        "# Creat a path name for image Id's\n",
        "\n",
        "filenames = [\"drive/MyDrive/Colab Notebooks/Dog Vision/train/\" + fname + \".jpg\" for fname in labels_csv[ \"id\"]]\n",
        "\n",
        "# Check for forst 10 rows\n",
        "filenames[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPc6o0ROf8i4"
      },
      "outputs": [],
      "source": [
        "# Check whether number of filenames matches number of actual image files\n",
        "\n",
        "import os\n",
        "if len(os.listdir(\"/content/drive/MyDrive/Colab Notebooks/Dog Vision/train\")) == len(filenames):\n",
        "  print(\"Filename matches actual number of files ! Proceed.\")\n",
        "else:\n",
        "  print(\"File name not matched check target directory\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7TAV9sagiNN"
      },
      "outputs": [],
      "source": [
        "# one miore check\n",
        "Image(filenames[1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4Yxj8jzid-E"
      },
      "outputs": [],
      "source": [
        "labels_csv[\"breed\"][1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtGXPYoci0yu"
      },
      "source": [
        "Since we got our training image filepaths in a list,let's prepare our list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FN5efgFmkvmP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "labels = labels_csv[\"breed\"]\n",
        "labels = np.array(labels)\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bdt3keFBlfBx"
      },
      "outputs": [],
      "source": [
        "len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27pILvAcl4g6"
      },
      "outputs": [],
      "source": [
        "# See if the number of labels matches the number of filenames\n",
        "if len(labels) == len(filenames):\n",
        "  print(\"The number of labels matches the number of filenames\")\n",
        "else:\n",
        "  print(\"Number of labels does not matches the number of filenames, check the data directories\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KroAn8Q5mpV5"
      },
      "outputs": [],
      "source": [
        "# Find the unique label values\n",
        "unique_breeds = np.unique(labels)\n",
        "unique_breeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfO78gsBm0Ip"
      },
      "outputs": [],
      "source": [
        "# Turn a single label into am array of booleans\n",
        "print(labels[0])\n",
        "labels[0] == unique_breeds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3btxbE6njTq"
      },
      "outputs": [],
      "source": [
        "len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGsGnvZsnzZY"
      },
      "outputs": [],
      "source": [
        "# Turn every label into boolean array\n",
        "boolean_labels = [label == unique_breeds for label in labels]\n",
        "boolean_labels[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HabY4DgZoKF-"
      },
      "outputs": [],
      "source": [
        "len(boolean_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EX2_FzGKoYTo"
      },
      "outputs": [],
      "source": [
        "# Example: Turning boolean numbers into integers\n",
        "print(labels[0]) # orginal label\n",
        "print(np.where(unique_breeds==labels[0])) # index where the label occurs\n",
        "print(boolean_labels[0].argmax()) # index where the label occurs in boolean array\n",
        "print(boolean_labels[0].astype(int)) # there will be 1 where the sample label occurs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NM8epibfpdmB"
      },
      "outputs": [],
      "source": [
        "print(labels[1])\n",
        "print(boolean_labels[1].astype(int))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUTPBtV1pxcs"
      },
      "outputs": [],
      "source": [
        "boolean_labels[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erQns_wqqDyI"
      },
      "outputs": [],
      "source": [
        "filenames[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsDwLDixqHKh"
      },
      "source": [
        "# Creating our own validation set\n",
        "Since the dataset from kaggle does'nt come with validation set,we're going to create our own."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqUJK0srskf0"
      },
      "outputs": [],
      "source": [
        "# setup x and y variables\n",
        "x = filenames # our data (images)\n",
        "y = boolean_labels # labels of the images in boolean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6SegqPfs241"
      },
      "outputs": [],
      "source": [
        "len(filenames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFkENqU7s6DD"
      },
      "source": [
        "We're going to strt off with ~1000 images and increase as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUGE8YMttP5a"
      },
      "outputs": [],
      "source": [
        "# Set number of images to use for experimenting\n",
        "NUM_IMAGES = 1000 #@param {type:\"slider\",min:1000,max:10000,step:1000}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLUY65q1t3z_"
      },
      "outputs": [],
      "source": [
        "# let's split our data into train and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split the data into train and validation set of total NUM_IMAGES size\n",
        "x_train, x_val, y_train, y_val = train_test_split(x[:NUM_IMAGES],\n",
        "                                                  y[:NUM_IMAGES],\n",
        "                                                  test_size=0.2,\n",
        "                                                  random_state=42)\n",
        "\n",
        "len(x_train), len(x_val), len(y_train), len(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sreK_TENvC5q"
      },
      "outputs": [],
      "source": [
        "# let's check\n",
        "x_train[:5],y_train[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zkBWKMyvS19"
      },
      "source": [
        "## Preprocessing Images (turning images into Tensors)\n",
        "\n",
        "To Preprocess our images into Tensor's we're going to write a function that does a few things.\n",
        "\n",
        "1. Take an image file as input.\n",
        "2. Use TensorFlow to read the file and save it to a variable,`image`\n",
        "3. Turn our `image` (a jpg) into tensors\n",
        "4. Normalize our image (convert colour channel values from 0-255 to 0-1).\n",
        "5. Resize the `image` to be a shape of (224,224).\n",
        "6. Return the modified `image`.\n",
        "\n",
        "Before we do,let's see how does an image look like when we import it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjmAc4EFOYc5"
      },
      "outputs": [],
      "source": [
        "# Convert image into numpy array\n",
        "from matplotlib.pyplot import imread\n",
        "image = imread(filenames[20])\n",
        "image.shape # return height,width,colour channel number(RGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKSUHfS6OuHy"
      },
      "outputs": [],
      "source": [
        "image[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AH2Pb8XAO6m_"
      },
      "outputs": [],
      "source": [
        "# turn image into tensor\n",
        "tf.constant(image)[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jusq6YrjPIeR"
      },
      "source": [
        "Now we have seen what an image looks like as a Tensor,let's make a function to preprocess them.\n",
        "\n",
        "We'll create a function to.\n",
        "\n",
        "\n",
        "1. Take an image file as input.\n",
        "2. Use TensorFlow to read the file and save it to a variable,`image`\n",
        "3. Turn our `image` (a jpg) into tensors\n",
        "4. Normalize our image (convert colour channel values from 0-255 to 0-1).\n",
        "5. Resize the `image` to be a shape of (224,224).\n",
        "6. Return the modified `image`.\n",
        "\n",
        "More information on loading images in TensorFlow can be seen here: https://www.tensorflow.org/tutorials/load_data/images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEKMYHg0If-k"
      },
      "outputs": [],
      "source": [
        "# Define a image size\n",
        "IMG_SIZE = 244\n",
        "\n",
        "# Create a function for preprocessing images\n",
        "def process_image(img_path,img_size = IMG_SIZE):\n",
        "  \"\"\"\n",
        "  Take an image file path and converts the image into Tensor\n",
        "  \"\"\"\n",
        "\n",
        "  # Read in an image file\n",
        "  image = tf.io.read_file(img_path)\n",
        "  # Turn the jpg image into Numerical Tensor with 3 colour channels (Red,Green,Blue)\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  # Convert colour channel values from 0-255 to 0-1\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  # Resize the image to desired value (224,224)\n",
        "  image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n",
        "\n",
        "  return image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aik-521bKWGN"
      },
      "source": [
        "## Turn our data into batches\n",
        "\n",
        "why should we turn our data into batches?\n",
        "\n",
        "Let's say you're trying to process 10,000+ images in one go.They all might not fit into memory(GPU shortage occur).\n",
        "\n",
        "So that's why we do 32(batch size) images at a time (you can manually adjust the batch size if needed).\n",
        "\n",
        "In order to use Tensorflow effectively, we need our data in the form of Tensor tuples which look like this:\n",
        "`(image, label)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1y03ewF3P0uC"
      },
      "outputs": [],
      "source": [
        "# Create a simple function to return a tuple (image, label)\n",
        "def get_image_label(image_path, label):\n",
        "  \"\"\"\n",
        "  Takes an image file path name and the associated label,\n",
        "  processes the image and returns a tuple of (image,label).\n",
        "  \"\"\"\n",
        "  image = process_image(image_path)\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MD51ONytQyci"
      },
      "outputs": [],
      "source": [
        "# Demo of the above\n",
        "(process_image(x[42],  tf.constant(y[42])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25Zmxmr3Q-8t"
      },
      "source": [
        "Now we have got a way to turn our data into tuples of Tensors in the form:`(image,label),let's\n",
        "make a function to turn all of our data (`x` & `y`) into batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4T1rkZt_SiXb"
      },
      "outputs": [],
      "source": [
        "# Define the batch size, 32 is a good start\n",
        "BATCH_SIZE = 42\n",
        "\n",
        "# Create a function to turn dat into batches\n",
        "def create_data_batches(x,y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n",
        "\n",
        "  \"\"\"\n",
        "  Creates batches of data out of image (y) and label (y) pairs.\n",
        "  Shuffles the data if it's training data and does'nt shuffle if it's validation data.\n",
        "  Also accepts the data as input (no labels).\n",
        "  \"\"\"\n",
        "  # If the data is a test dataset, we probably don't have any labels\n",
        "  if test_data:\n",
        "    print(\"Creating test data batches...\")\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(x))) # only filepaths (no labels)\n",
        "    data_batch = data.map(process_image).batch(BATCH_SIZE)\n",
        "    return data_batch\n",
        "\n",
        "  # If the data is valid dataset, we don't need to shuffle it\n",
        "  elif valid_data:\n",
        "    print(\"Create validation data batches...\")\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n",
        "                                               tf.constant(y))) #labels\n",
        "    data_batch = data.map(process_image).batch(BATCH_SIZE)\n",
        "    return data_batch\n",
        "\n",
        "  else:\n",
        "    print(\"Creating training data batches...\")\n",
        "    # Turn filepaths and labels into Tensors\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(x),\n",
        "                                               tf.constant(y)))\n",
        "    # Shuffling pathnames and labels before mapping the image processor function is faster than shuffling images\n",
        "    data = data.shuffle(buffer_size=len(x))\n",
        "\n",
        "    # Create (image,label) tuples (this also turns the image path into a preprocessed image)\n",
        "    data = data.map(get_image_label)\n",
        "\n",
        "    # Turn the training data into batches\n",
        "    data_batch = data.batch(BATCH_SIZE)\n",
        "\n",
        "  return data_batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCL9JrfNSmDc"
      },
      "outputs": [],
      "source": [
        "# Create training and validation batches\n",
        "train_data = create_data_batches(x_train,y_train)\n",
        "val_data = create_data_batches(x_val,y_val,valid_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8vLG-Apdl-z"
      },
      "outputs": [],
      "source": [
        "# Checkout the differnt attributes of our data batches\n",
        "train_data.element_spec, val_data.element_spec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmUqsFQad8S6"
      },
      "source": [
        "## Visualizing Data Batches\n",
        "\n",
        "Our data is now in batches, however these can be a little hard to understand/comprehend,let's visulize them!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmweBoPpeUBS"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a function for viewing images in the data batch\n",
        "def show_25_images(images, labels):\n",
        "  \"\"\"\n",
        "  Displays a plot of 25 images and their labels from a data batch\n",
        "  \"\"\"\n",
        "  # Setup the figure\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  # Loop through 25 (for displaying 25 images)\n",
        "  for i in range(25):\n",
        "    # Create subplots(5 rows, 5 columns)\n",
        "    ax = plt.subplot(5, 5, i+1)\n",
        "    # Display an image\n",
        "    plt.imshow(images[i])\n",
        "    # Add the image label as the title\n",
        "    plt.title(unique_breeds[labels[i].argmax()])\n",
        "    # Turn the grid off\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4efkwQGy3fdR"
      },
      "outputs": [],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dUlf6Ac3iPw"
      },
      "outputs": [],
      "source": [
        "# Now let's visualize the data in a training batch\n",
        "train_images, train_labels = next(train_data.as_numpy_iterator())\n",
        "show_25_images(train_images, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nk7qN9e4IPP"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.range(2)\n",
        "for element in dataset:\n",
        "  print(element)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd9MSC2C-ia6"
      },
      "outputs": [],
      "source": [
        "# # Now let's visualize the data in our validation batch\n",
        "# val_images, val_labels = next(val_data.as_numpy_iterator())\n",
        "# show_25_images(train_images, val_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygF600aR-p5S"
      },
      "source": [
        "## Building a model\n",
        "\n",
        "Before we build a model,there are a few things we need to define:\n",
        "\n",
        "- The input shape (our image shape, in the form of Tensors) to our model.\n",
        "- The output shape (image labels, in the form of Tensors ) of our model.\n",
        "- The URL of the model we want to use from Tensorflow Hub - https://www.kaggle.com/models/google/mobilenet-v2/tensorFlow2/130-224-classification/1?tfhub-redirect=true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leOfi_flAPxq"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2gvn4YiAZ8c"
      },
      "outputs": [],
      "source": [
        "# setup input shape to the model\n",
        "\n",
        "# reinstantiate the IMG_SIZE\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "INPUT_SHAPE = [None, IMG_SIZE , IMG_SIZE, 3] # batch, height, width, colour channels\n",
        "\n",
        "# Setup output shape of our model\n",
        "OUTPUT_SHAPE = len(unique_breeds)\n",
        "\n",
        "# Setup model URL form TensorFlow Hub\n",
        "MODEL_URL = \"https://www.kaggle.com/models/google/mobilenet-v2/tensorFlow2/130-224-classification/1?tfhub-redirect=true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35F2PqeoBj9s"
      },
      "outputs": [],
      "source": [
        "INPUT_SHAPE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkFCZMVfBp7e"
      },
      "source": [
        "Now we've have got our inputs,outputs and model ready to go. Let's put them together into keras deep learning model.\n",
        "\n",
        "Knowing this,let's create a function which:\n",
        "\n",
        "- Takes the input shape,output shape and the model we've chosen as parameters.\n",
        "- Defines the layers in a keras model in sequential fashion(do this first,then this,then that)\n",
        "- Compiles the model (says it should be evaluated and improved).\n",
        "- Builds the model(tells the model the input shape it'll be getting).\n",
        "- Returns the model.\n",
        "\n",
        "All of these steps can be found here: https://www.tensorflow.org/guide/keras/overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFaU--lpbBIk"
      },
      "outputs": [],
      "source": [
        "# Create a function which builds a keras model\n",
        "\n",
        "def create_model(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE, model_url=MODEL_URL):\n",
        "  print(\"Building model with:\",MODEL_URL)\n",
        "\n",
        "  # Setup the model layers\n",
        "  model = tf.keras.Sequential([\n",
        "      hub.KerasLayer(MODEL_URL), # Layer 1 (input layer)\n",
        "      tf.keras.layers.Dense(units=OUTPUT_SHAPE,\n",
        "                            activation=\"softmax\") # Layer 2 (output layer)\n",
        "  ])\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(\n",
        "      loss = tf.keras.losses.CategoricalCrossentropy(),\n",
        "      optimizer=tf.keras.optimizers.Adam(),\n",
        "      metrics=[\"accuracy\"]\n",
        "  )\n",
        "\n",
        "  # Build the model\n",
        "  model.build(INPUT_SHAPE)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIWW1EJvcbLL"
      },
      "outputs": [],
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating callbacks\n",
        "\n",
        "Callbacks are helper functions a model can use during to do such things as save its progress,check its progress or stop training early if\n",
        "a model stops improving.\n",
        "\n",
        "We'll create two callbacks, one for TensorBoard whcih helps track our models\n",
        "progress and another for early stopping which prevents our model from training for too long.\n",
        "\n",
        "### TensorBoard Callback\n",
        "\n",
        "To setup a TensorBoard callback, we need to do 3 things:\n",
        "\n",
        "1. Load the TensorBoard notebook extension ‚úÖ\n",
        "2. Create a TensorBoard callback which is able to save logs to a directory and pass it to our model's `fit()` function. ‚úÖ\n",
        "3. Visualize our models training logs with the `%tensorboard` magic function(we'll do this after model training).\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard"
      ],
      "metadata": {
        "id": "qYa4FqhVcqG5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwU3eBcsd1RA"
      },
      "outputs": [],
      "source": [
        "# Load TensorBoard notebook extension\n",
        "\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18awY6OOep9Z"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "# Create a function to build a TensorFlow callback\n",
        "def create_tensorboard_callback():\n",
        "  # Create a log directory for storing TensorBoard logs\n",
        "  logdir = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/Dog Vision/logs\",\n",
        "                        # Make it so the logs get tracked whenever we run an experiment\n",
        "                        datetime.datetime.now().strftime(\"%d%m%Y-%H%M%S\"))\n",
        "  return tf.keras.callbacks.TensorBoard(logdir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Early Stopping Callback\n",
        "\n",
        "Early stopping helps stop our model from overfitting by stopping training if a certain evaluation metric stops improving.\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\n"
      ],
      "metadata": {
        "id": "fu5L3eYHjHle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create early stopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                  patience=3)\n"
      ],
      "metadata": {
        "id": "ttKVlztRlXMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a model (on subset of data)\n",
        "\n",
        "Our first model is only going to train on 1000 images, to make sure everything is working."
      ],
      "metadata": {
        "id": "NrpqFuwmltQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 60 # @param {type:\"slider\", min:10, max:100, step:10 }"
      ],
      "metadata": {
        "id": "_1cb-gi2qEoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check to make sure we're still running on a GPU\n",
        "print(\"GPU\", \"available(YES!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")"
      ],
      "metadata": {
        "id": "9Zk6OomnqgF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  Let's create a function which trains a model.\n",
        "\n",
        "  - Create a model using `create_model()`\n",
        "  - Setup a TensorBoard callback using `create_tensorboard_callback()`\n",
        "  - Call the `fit()` function on our model passing it the training data,validation data, number of epochs to train for (`NUM_EPOCHS`) and the callbacks we'd like\n",
        "  to use.\n",
        "  - Return the model"
      ],
      "metadata": {
        "id": "Cu1lEWzRq6UA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a function to train and return a trained model\n",
        "def train_model():\n",
        "  \"\"\"\n",
        "  Trains a given model and returns the trained version\n",
        "  \"\"\"\n",
        "  # Create a model\n",
        "  model = create_model()\n",
        "\n",
        "  # Create new TensorBoard session everytime we train a model\n",
        "  tensorboard = create_tensorboard_callback()\n",
        "\n",
        "  # Fit the model to the data passing it the callbacks we created\n",
        "  model.fit(x=train_data,\n",
        "            epochs=NUM_EPOCHS,\n",
        "            validation_data = val_data,\n",
        "            validation_freq = 1,\n",
        "            callbacks = [tensorboard, early_stopping])\n",
        "  # Return the fitted model\n",
        "  return model"
      ],
      "metadata": {
        "id": "8ahY5MmKr3Zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model to the data\n",
        "model = train_model()"
      ],
      "metadata": {
        "id": "weAUVkabsuOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f89wo0BLs7mT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ywwu-b-etnqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ImW2W8BPuoA8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}